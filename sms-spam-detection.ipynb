{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing necessary libararies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/induda/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#TO overcome SSL ERROR while downloading stopwords from NLTK\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/ml/spam.csv', sep = ',', header = 0, quotechar = '\"', encoding = 'ISO-8859-1' )\n",
    "data1 = data.iloc[:,1:2]\n",
    "label_series = data['v1'].map({'ham':0, 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes score 0.979181622398\n",
      "confusion matrix for NB:  [[1173   23]\n",
      " [   6  191]]\n",
      "AdaBoost score 0.962670495334\n",
      "confusion matrix for AD:  [[1173   23]\n",
      " [   6  191]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "#Cleaning data\n",
    "corpus = []\n",
    "for i in range(0,len(data1)):\n",
    "    sms = re.sub('[^a-zA-Z]', ' ', data1['v2'][i]).lower().split()\n",
    "    sms = [ps.stem(word) for word in sms if not word in set(stopwords.words('english'))]\n",
    "    sms = ' '.join(sms)\n",
    "    corpus.append(sms)\n",
    "\n",
    "#Counting the frequency with CountVectorizer\n",
    "cv = CountVectorizer(decode_error = 'ignore')\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = label_series.values\n",
    "\n",
    "#Importing Classifiers and splitting dataset in train and test\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "#Naive Bayes Classifier\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train,y_train)\n",
    "nb_pred = nb.predict(X_test)\n",
    "print \"Naive Bayes score\", nb.score(X_test,y_test)\n",
    "print \"confusion matrix for NB: \", confusion_matrix(y_test, nb_pred)\n",
    "\n",
    "#AdaBoost Classifier\n",
    "ad = AdaBoostClassifier()\n",
    "ad.fit(X_train,y_train)\n",
    "ad_pred = nb.predict(X_test)\n",
    "print \"AdaBoost score\", ad.score(X_test,y_test)\n",
    "print \"confusion matrix for AD: \", confusion_matrix(y_test, ad_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes score 0.960516870065\n",
      "confusion matrix for NB:  [[1195    1]\n",
      " [  54  143]]\n",
      "AdaBoost score 0.9720028715\n",
      "confusion matrix for AD:  [[1195    1]\n",
      " [  54  143]]\n"
     ]
    }
   ],
   "source": [
    "#Counting the frequency with TfidfVectorizer\n",
    "tv = TfidfVectorizer(decode_error = 'ignore')\n",
    "X_tv = tv.fit_transform(corpus).toarray()\n",
    "y_tv = label_series.values\n",
    "\n",
    "#Importing Classifiers and splitting dataset in train and test\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(X_tv,y_tv, test_size = 0.25, random_state = 0)\n",
    "\n",
    "#Naive Bayes Classifier\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train,y_train)\n",
    "nb_pred = nb.predict(X_test)\n",
    "print \"Naive Bayes score\", nb.score(X_test,y_test)\n",
    "print \"confusion matrix for NB: \", confusion_matrix(y_test, nb_pred)\n",
    "\n",
    "#AdaBoost Classifier\n",
    "ad = AdaBoostClassifier()\n",
    "ad.fit(X_train,y_train)\n",
    "ad_pred = nb.predict(X_test)\n",
    "print \"AdaBoost score\", ad.score(X_test,y_test)\n",
    "print \"confusion matrix for AD: \", confusion_matrix(y_test, ad_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
